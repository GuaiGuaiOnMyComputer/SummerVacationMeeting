{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Transfer Learning for Computer Vision Tutorial\n",
        "\n",
        "Adapted from: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "\n",
        "\n",
        "**Author**: [Sasank Chilamkurthy](https://chsasank.github.io)\n",
        "\n",
        "In this tutorial, you will learn how to train a convolutional neural network for image classification using transfer learning. You can read more about the transfer learning at [cs231n notes](https://cs231n.github.io/transfer-learning/)_ \n",
        "Quoting these notes,\n",
        "\n",
        "    In practice, very few people train an entire Convolutional Network\n",
        "    from scratch (with random initialization), because it is relatively\n",
        "    rare to have a dataset of sufficient size. Instead, it is common to\n",
        "    pretrain a ConvNet on a very large dataset (e.g. ImageNet, which\n",
        "    contains 1.2 million images with 1000 categories), and then use the\n",
        "    ConvNet either as an initialization or a fixed feature extractor for\n",
        "    the task of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resnet18 for Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What is Resnet18\n",
        "\n",
        "A ```resnet18``` is a pretrained deep feed forward neural network with 17 convolution layers and 1 fully connected layer. According to [this thesis](ResnetRef.pdf), introducing feed forward shortcuts to a deeply stacked network can further increase the accuracy of the model. Such feed forward shortcuts can counter the problem with gradient vanishing by adding the input of the layer block to its output. A layer block is a pair of convolution layers in different sizes. During training, if the convolution layers in the layer block is not helpful, its weights can be lowered and thus the output of the layer block can be more dependent to its input, essentially bypassing the convolution layers within.\n",
        "\n",
        "The original ```Resnet18``` is designed to classify 1000 different labels, therefor its final layer is a fully connected layer taking in the features from the previous convolution layer and outputs 1000 scores for each label. The fully connected layer can be modified to different sizes to output different number of classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![fff](img/Resnet18.svg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from os.path import join"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "\n",
        "The raw data can be downloaded from [here](https://download.pytorch.org/tutorial/hymenoptera_data.zip). \n",
        "This dataset is a very small subset of imagenet.\n",
        "Please extract the zip file into the same directory containing this notebook file.\n",
        "\n",
        "We will use ```torchvision``` and ```torch.utils.data``` packages for loading the\n",
        "data.\n",
        "\n",
        "The problem we're going to solve today is to train a model to classify\n",
        "**ants** and **bees**. We have about 120 training images each for ants and bees.\n",
        "There are 75 validation images for each class. Usually, this is a very\n",
        "small dataset to generalize upon, if trained from scratch. Since we\n",
        "are using transfer learning, we should be able to generalize reasonably\n",
        "well.\n",
        "\n",
        "Here are some images that will be used for training:\n",
        "\n",
        "![](hymenoptera_data/train/ants/560966032_988f4d7bc4.jpg)\n",
        "![](hymenoptera_data/train/bees/1232245714_f862fbe385.jpg)\n",
        "![](hymenoptera_data/train/bees/39672681_1302d204d1.jpg)\n",
        "![](hymenoptera_data/train/ants/9715481_b3cb4114ff.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "DATA_DIR:str = join('SummerVacationMeeting', 'W4_TransferLearning', 'hymenoptera_data')\n",
        "BATCH_SIZE = 6\n",
        "\n",
        "data_transforms:dict[str, transforms.Compose] = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\"\"\" \n",
        "create dataset objects for training & validation datasets and store them into image_datasets dictionary\n",
        "torchvision.datasets.ImageFolder inherits torch.utils.data.Dataset class \n",
        "\"\"\"\n",
        "training_dataset = ImageFolder(\n",
        "    root = join(DATA_DIR, 'train'),\n",
        "    transform = data_transforms['train']\n",
        ")\n",
        "val_dataset = ImageFolder(\n",
        "    root = join(DATA_DIR, 'val'),\n",
        "    transform = data_transforms['val']\n",
        ")\n",
        "image_datasets: dict[str, ImageFolder] = {'train': training_dataset, 'val': val_dataset}\n",
        "\n",
        "\n",
        "\"\"\" create dataloader objects for training & validation dataloaders and store them into dataloaders dictionary \"\"\"\n",
        "train_dataloader = DataLoader(training_dataset, \n",
        "    batch_size = BATCH_SIZE, \n",
        "    shuffle = True, \n",
        "    num_workers = 4)\n",
        "val_dataloader = DataLoader(val_dataset, \n",
        "    batch_size = BATCH_SIZE, \n",
        "    shuffle = True, \n",
        "    num_workers = 4)\n",
        "dataloaders:dict[str, DataLoader] = {'train': train_dataloader, 'val': val_dataloader}\n",
        "\n",
        "dataset_sizes = {train_val: len(image_datasets[train_val]) for train_val in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train All Layers and Weights in Resnet18\n",
        "\n",
        "Pytorch provides a ```models.resnet18``` class and its pretrained weights. The following cell makes ```model_ft``` an instance of ```resnet18``` and replaces its pretrained final fully connected layer with our own custom fully connected layer that takes in the same number of inputs from the previous convolution layer and outputs the scores for the 2 labels. This new fully conneced layer is to be trained.\n",
        "\n",
        "![entire resnet to be trained](img/Resnet18_learn_all.svg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet18(weights = \"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "The possible weight options for resnet18 are \"DEFAULT\", \"IMAGENET1K_V1\" or None\n",
        "If the weight argument is left blank or set to None, no weights for resent18 will be loaded\n",
        "According to https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L10 option \"DEFAULT\" and \"IMAGENET_1K_V!\" loades the same set of weights\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" \n",
        "Replace the last fully connected layer in Resnet18 that takes in model_ft.fc.in_features number of features and out put 1000 class scores with our own custom\n",
        "fully connected layer that takes in model_ft.fc.in_features features and outputs 2 class scores. \n",
        "\"\"\"\n",
        "model_ft.fc = nn.Linear(model_ft.fc.in_features, 2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and Evaluate\n",
        "\n",
        "It should take around 15-25 min on CPU. On GPU though, it takes less than a minute.\n",
        "\n",
        "The training loop is written in a [seperate file](train_and_test_model.py). Both the training loop provided by the tutorial and the denestified version are present. For some reason, models trained using the denestified version performs significantly worse than the original versoin?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/3\n",
            "----------\n",
            "Train Loss: 0.6583 Acc: 0.6803\n",
            "Vali Loss : 0.0272 Acc: 0.9412\n",
            "Epoch 1/3\n",
            "----------\n",
            "Train Loss: 0.3695 Acc: 0.8484\n",
            "Vali Loss : 0.0498 Acc: 0.9281\n",
            "Epoch 2/3\n",
            "----------\n",
            "Train Loss: 0.3675 Acc: 0.8402\n",
            "Vali Loss : 0.0408 Acc: 0.9150\n",
            "Epoch 3/3\n",
            "----------\n",
            "Train Loss: 0.2871 Acc: 0.8730\n",
            "Vali Loss : 0.0367 Acc: 0.9150\n",
            "Training complete in 1m 33s\n",
            "Highest validation accuracy is 0.941\n"
          ]
        }
      ],
      "source": [
        "from train_and_test_model import my_train_model\n",
        "model_ft = my_train_model(model_ft, criterion, dataloaders, dataset_sizes, optimizer_ft, exp_lr_scheduler, DEVICE, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The training loop provided by the tutorial is not called'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"The training loop provided by the tutorial is not called\"\"\"\n",
        "# from train_and_test_model import tutorial_train_model\n",
        "# model_ft = model_ft.to(DEVICE)\n",
        "# model_ft = tutorial_train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, dataset_sizes, DEVICE, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resnet as Fixed Feature Extractor\n",
        "\n",
        "Retraining all the layers, including those that were pretrained in ```resnet18``` might be unnecessary. The first 17 layers in this network are convolution layers. These convolution layers act like feature extractors, or filters, operating on given images. Their parameters and weights might have been optimized when we load them and don't require futher training.\n",
        "\n",
        "What requires training is the custom fully connected layer we have just added to this network. To train only the final layer and not train the others, we need to freeze all the network except the final one. We need to set ```requires_grad = False``` to freeze the parameters so that the gradients are not computed in ```backward()```. \n",
        "You can read more about this in the documentation\n",
        "[here](https://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward)_.\n",
        "\n",
        "![only train the last layer resnet](img/Resnet18_learn_only_last_layer.svg)\n",
        "\n",
        "By only training the custom fully connected layer, the model can be trained faster and more efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/3\n",
            "----------\n",
            "Train Loss: 0.5746 Acc: 0.6885\n",
            "Vali Loss : 0.0377 Acc: 0.9346\n",
            "Epoch 1/3\n",
            "----------\n",
            "Train Loss: 0.4205 Acc: 0.8115\n",
            "Vali Loss : 0.0503 Acc: 0.8824\n",
            "Epoch 2/3\n",
            "----------\n",
            "Train Loss: 0.5282 Acc: 0.7582\n",
            "Vali Loss : 0.0294 Acc: 0.9412\n",
            "Epoch 3/3\n",
            "----------\n",
            "Train Loss: 0.3651 Acc: 0.8525\n",
            "Vali Loss : 0.0277 Acc: 0.9412\n",
            "Training complete in 1m 12s\n",
            "Highest validation accuracy is 0.941\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from train_and_test_model import my_train_model\n",
        "model_conv = my_train_model(model_conv, criterion, dataloaders, dataset_sizes, optimizer_conv, exp_lr_scheduler, DEVICE, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The training loop provided by the tutorial is not called'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"The training loop provided by the tutorial is not called\"\"\"\n",
        "# from train_and_test_model import tutorial_train_model\n",
        "# model_conv = tutorial_train_model(model_conv, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, dataset_sizes, DEVICE, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "This demo explains the transfer training feature provided in Pytorch. If we wish to create a network, it's probably not necessary to start from scratch. There are pretrained networks such as ```resnet``` that can be modified to suit our needs. By setting the ```requires_grad``` attribute of each parameter in a network to ```False```, we can avoid training the parameters and speed up the process while probably not loose model performance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
