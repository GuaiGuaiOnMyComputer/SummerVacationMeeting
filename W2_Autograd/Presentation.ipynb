{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Autogradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "[Autograd Api Doc](https://pytorch.org/docs/stable/autograd.html)\n",
    "\n",
    "[Back Propagation](https://medium.com/ai-academy-taiwan/bacn-propagation-3946e8ed8c55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During neural networn tarining, gradient decent is a common way of determining how the weights within a neural networn should be adjusted. By calculating the parital derivatives of the loss function to a given weight, we can see the direction that a given weight should be adjusted. When the partial derivative reaches 0, the given weight is possibly at its optimal value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following simple neural networn with 2 input features and 2 layers:\n",
    "\n",
    "<img src=\"img/SimpleNeuralNetwork.jpg\" width=\"900\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the inpact of $w^{1}_{11}$ on the loss function, calculate the partial derivative \n",
    "$\\frac{\\partial L}{\\partial w^{1}_{11}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\hat{y}:ground truth\\\\\n",
    "L = \\frac{1}{2n} \\sum_{k=1}^n (y - \\hat{y})^2, n=batch size\\\\\n",
    "\\text{Assume batch size n = 1, then}L = \\frac{1}{2}(y - \\hat{y})^2 \\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial w^{1}_{11}} &= \\frac{\\partial L}{\\partial z^3_1} \\frac{\\partial z^3_1}{\\partial w^{1}_{11}}\\\\\n",
    "&= \\frac{\\partial L}{\\partial z^3_1} (\\frac{\\partial z^3_1}{\\partial a^2_1} \\frac{\\partial a^2_1}{\\partial z^2_1} \\frac{\\partial z^2_1}{\\partial a^1_1} \\frac{\\partial a^1_1}{\\partial z^1_1} \\frac{\\partial z^1_1}{\\partial w^1_1} + \\frac{\\partial z^3_1}{\\partial a^2_2} \\frac{\\partial a^2_2}{\\partial z^2_2} \\frac{\\partial z^2_2}{\\partial a^1_1} \\frac{\\partial a^1_1}{\\partial z^1_1} \\frac{\\partial z^1_1}{\\partial w^1_1}) \\\\\n",
    "&= \\frac{\\partial L}{\\partial z^3_1} (\\frac{\\partial z^3_1}{\\partial a^2_1} \\frac{\\partial a^2_1}{\\partial z^2_1} \\frac{\\partial z^2_1}{\\partial a^1_1} + \\frac{\\partial z^3_1}{\\partial a^2_2} \\frac{\\partial a^2_2}{\\partial z^2_2} \\frac{\\partial z^2_2}{\\partial a^1_1})*( \\frac{\\partial a^1_1}{\\partial z^1_1} \\frac{\\partial z^1_1}{\\partial w^1_1}) \\\\\n",
    "&= \\frac{\\partial L}{\\partial z^3_1} (\\sum_{n=1}^2\\frac{\\partial z^3_1}{\\partial a^n_1} \\frac{\\partial a^n_1}{\\partial z^n_1} \\frac{\\partial z^n_1}{\\partial a^1_1}) * ( \\frac{\\partial a^1_1}{\\partial z^1_1} \\frac{\\partial z^1_1}{\\partial w^1_1}) \\text{ since } y = z^3_1 \\text{ then } \\partial z^3_1 = \\partial y\\\\\n",
    "\n",
    "&= \\frac{\\partial L}{\\partial y} (\\sum_{n=1}^2\\frac{\\partial z^3_1}{\\partial a^n_1} \\frac{\\partial a^n_1}{\\partial z^n_1} \\frac{\\partial z^n_1}{\\partial a^1_1}) * ( \\frac{\\partial a^1_1}{\\partial z^1_1} \\frac{\\partial z^1_1}{\\partial w^1_1})\\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\text{subsitude}\\\\\n",
    "&\\frac{\\partial L}{\\partial y} = \\frac{\\partial}{\\partial y}[\\frac{1}{2}(y-\\hat{y})^2] = y - \\hat{y}\\\\\n",
    "&\\frac{\\partial z^3_1}{\\partial a^2_1}=\\frac{\\partial}{\\partial a^2_1}{(w^3_{11} a^2_1 + w^3_{12} a^2_2)} = w^3_{11}\\\\\n",
    "&\\frac{\\partial a^n_1}{\\partial z^n_1} = \\frac{\\partial f(z^n_1)}{\\partial z^n_1}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial w^{1}_{11}} = (y - \\hat{y}) \\sum_{n=1}^2(w^3_{11}\\frac{\\partial f(z^n_1)}{\\partial z^n_1} w^2_{11})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], requires_grad=True)\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([  1.,   4.,   9.,  16.,  25.,  36.,  49.,  64.,  81., 100.],\n",
      "       grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(0, 10, 1, dtype = torch.float32, requires_grad = True)\n",
    "print(x)\n",
    "x = x + 1\n",
    "print(x)\n",
    "x **= 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
